# Diversion-Hackathon
<!DOCTYPE html>
<html>
    <head>
        <title>Ez-Viz</title>
        <meta charset="utf-8">
        <meta name = "viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="styles.css">
    </head>
    <body>
        <h1>Importing necessary models :</h1>
        <img src="models.jpg" alt="models required for Ez-Viz">
        <h3>
            <ul>
                <li><i>RandomForestClassifier</i> : An ensemble learning method using multiple decision trees to improve accuracy and reduce overfitting. Ideal for classification tasks.</li>
                <li><i>GradientBoostingClassifier</i> : Another ensemble technique that builds models sequentially, optimizing errors from previous models. Suitable for complex datasets.</li>
                <li><i>AdaBoostClassifier</i> : An adaptive boosting method that combines weak classifiers iteratively to form a strong classifier. Effective for reducing bias and variance.</li>
                <li><i>LinearRegression</i> : A basic model for predicting continuous values by fitting a linear relationship between features and targets.</li>
                <li><i>LogisticRegression</i> : A statistical model for binary or multi-class classification problems using a sigmoid function for prediction.</li>
                <li><i>DecisionTreeClassifier</i> : A tree-based model that splits data into branches based on feature conditions for classification.</li>
                <li><i>SVC (Support Vector Classifier)</i> : A model that finds the optimal hyperplane to separate data into classes, effective for high-dimensional spaces.</li>
                <li><i>KNeighborsClassifier</i> : A simple algorithm that classifies a sample based on the majority class among its 'k' nearestÂ neighbors.</li>
            </ul>
        </h3>
        <h1>Seperating numericals and categorical values :</h1>
        <img src="sep nem and cat val" alt="image of the code for the same">
</body>

</html>